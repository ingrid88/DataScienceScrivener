{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
\cocoascreenfonts1{\fonttbl\f0\fnil\fcharset0 Cochin;}
{\colortbl;\red255\green255\blue255;}
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural

\f0\fs28 \cf0 Easy for seller to put item on site, data scientists can easily use that to find simliar items\
As a merchandiser team, we want to provide a way to find similar items\
Maybe item you clicked on is not good enough for you (not good price, used etc\'85) \
Ebay and seller and buyer want to help complete the purchase,   product id with database\
A lot of items are unique, rare, do not have a product id\
\
Eg. If you want to list a tshirt, pen, dres, etc\'85 we still need to be able to group these items\
So we can use the title and the image to help do this. \
The viewpoint etc\'85. Makes it hard to find similar items\'85 using word 2 vecs, neural networks\'85 enabling us to find similar items. \
We try to provide complimentary items\'85. Things that are usually bought together with the alreay purchased item\'85. We have to use some kind o ffuzzy representation made up of by the image and the title. \
We are looking for engineers, machine learning engineers, they need deep learning at EBAY. \
\
\
Meeting sponsors are altoros and ebay: \
In video, center\'85. Power the computers in car driving\'85. Nvidia gpu\
{\field{\*\fldinst{HYPERLINK "http://www.nvidia.com/object/geforce_family.html"}}{\fldrslt http://www.nvidia.com/object/geforce_family.html}}\
\
DEEP LEARNING topics\
Financial services\
Embedded systems (gpus, autonomous cars)\
Health care applications\
\
Best practices\'85. Into production\
Loading and unloading models\'85. \
\
San Hose gpu conference hosted by envidia\
\
DaVinci - deep learning nlp backgrounds\
{\field{\*\fldinst{HYPERLINK "http://dev.io"}}{\fldrslt DEV.io}}\'85\
\
Rafal Jozefowicz from google brain: tensorflow under the covers\
NLP applications (using neural networks) Looking to hire\
\
Tensor flow is an open source software library for numerical computation using data flow graphs\
Data transformation pipeline\'85. It adds a layer of abstraction. Separates graph creation from computations\'85 you can more easily run this part of graph on the graphics card or other machine. This separation of graph creation and computation is valuable\
(Labels + (Biases + (weights + examples) \'97> Matmul )\'97> add \'97> RElu \'97> Xent)\
\
Key features are deep flexivility, true prortability, connet research and production, auto differentation, language options, \'85\'85\
\
Written in C++, python front end as well\'85. \
\
Entropy, Tensor board?\
\
{\field{\*\fldinst{HYPERLINK "http://tensorflow.githubb.io/serving"}}{\fldrslt Tensorflow.githubb.io/serving}}\'85. Abstraction to help run experiments in production\
\
Eg. Language modeling: good/correct sentences should get higher probabilities than wrong ones\
It is a sequential  problem: what possible things user might have said\'85..\
Use speech recognition, machine translation , spelling correction\
\
\
\
Exploring the limits of language modeling: {\field{\*\fldinst{HYPERLINK "http://arxiv.org/abs/1602.02410"}}{\fldrslt arxiv.org/abs/1602.02410}}\
\
Recurrent neural network (RNN, or long short term meory LSTM\'85.  (THE model is quite slow)\
Asyncroneous stochastic training by breaking the dataset into pieces and hten sending the parameters computed from each machine back and somehow combining htem back\'85. (Grid search?)\
\
perplexicity vs model size \'85.. \
\
Rafa is {\field{\*\fldinst{HYPERLINK "mailto:rafjoz@gmail.com"}}{\fldrslt rafjoz@gmail.com}}\
\
Good for parallelizable processes (skitflow? )\
{\field{\*\fldinst{HYPERLINK "https://github.com/tensorflow/skflow"}}{\fldrslt https://github.com/tensorflow/skflow}}\
\
\
Kohonen, self organizing maps\
Lstms, gru vs lstm??\
{\field{\*\fldinst{HYPERLINK "https://en.wikipedia.org/wiki/Self-organizing_map"}}{\fldrslt https://en.wikipedia.org/wiki/Self-organizing_map}}\
\
How do they work\
1. Initialize random weights for each node in an m by n grid\
2. Select random training vector and identify a node with wieights that are clostest to the training vector\'85. This node is known as the best matching unit (BMU)\
3. Find all nodes within neighborhood of bmu and adjust their weights to mak them more smiilar to the BMU\
4. Adjust the laerning rate and neighborhood size\
5. Repeat steps 2 through 4 for a predetermined # of iterations. \
\
Heat map over time or something for each \
\
@Keithdavisiii\
Iamthevastidledhitchiker.github.io\
}