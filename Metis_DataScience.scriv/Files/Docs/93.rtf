{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
\cocoascreenfonts1{\fonttbl\f0\fnil\fcharset0 Cochin;}
{\colortbl;\red255\green255\blue255;}
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural

\f0\fs28 \cf0 Bary centric coordinates\
How to show a point is in a triangle\
\
There are other things \'85\'85 \
\
\
Domain, MC\
A. Problem : pca, \
\
B. Solution\
\
C. Implementation\
\
Tool set (aws, python) \'97 (getting data) shaping (machine learning (output, presentation d3 tablau\
\
\
Hadoop and map reduce\
\
\
The amount of data is growing at an exponential rate\'85 data in zettabytes\
What is memory vs computational issues\
\
Big data vs datascience (broader term\'85 coming up with something useful pertaining to small or big data)\
\
\
Paper published on mapreduced\'85. Yahoo came out wiht 1000 node cluster\
\
HDFS and Mapreduce\
Hdfs is a framework for distributing really large files among different machines\
Each data chunk is on 3 different servers, there are duplicates in case something breaks\
One main guy who keeps track of anything\
\
HDFS\
\
Hadoop is just a set of libraries kind of useed internally\
\
Yarn, resource management system (system admin would deal with this)\
Datascienctists mostly need to know where stuff is sitting (HDFS\
\
1. Set of libraries (common) with hadoop commands\
2. Yarn (research manager)\
3. HDFS (how stored and architecture)\
4. Map reduce (making It quicker)\
\
This is a framework for dealing with large amounts of data. \
\
\
\
MapReduce \
Mapreduce is made up of two functions map and reduce\
\
Map : load raw data sitting on different servers, filter and transform\
Output a key value pair\
\
Take each key value pair and the other server aggregates them by key\
\
\
Put some map code on each node and start your computation so that the data doesn\'92t have to move from it\'92s current location\
\
Sort and shuffle the key values so that now it knows all the keys from all these things go to the same reducer. Now all \'91apples\'92 sit on the same node\'85. \
\
The bottleneck can be taking the output and putting it back into hdfs (if its an iterative prcess)\
Arcitecture problems\
Optimal scheduling has to be done \
\
\
\
Hive is doing queries or very like-sql on data\
Pig - pig latin - etl processes\
Hbase, \
Sqoop (Sql to hadoop) relational database to hdfs\
Avro (seriealize data\'85)\
\
Use apache spark for iterative processess\
\
\
Anomaly detection \'97 \
\
You should be asking them who you will be interviewing with and what kind of questions they might ask \
\
Make a presentation earlier in the process and meet goal of what you want to present\
\
(Ranking over possible influencers for brand)\
(\
}